
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="CS231n: Deep Learning for Computer Vision">
      
      
      
        <link rel="canonical" href="https://eanyang7.github.io/cs231n/poster-2018/">
      
      
      
      
      <link rel="icon" href="../logo.jpg">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.3.1">
    
    
      
        <title>CS231n Poster Session 2018 - CS231n</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.046329b4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-5F8XNH7BCX"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-5F8XNH7BCX",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-5F8XNH7BCX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#list-of-projects-3-digit-number-is-id-to-locate-the-poster" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="CS231n" class="md-header__button md-logo" aria-label="CS231n" data-md-component="logo">
      
  <img src="../logo.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CS231n
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CS231n Poster Session 2018
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="选择当前语言">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/cs231n/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="https://cs231n.github.io/" hreflang="en" class="md-select__link">
              English(源网站)
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/cs231n" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/cs231n
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
  首页

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../courses/preparation/setup/" class="md-tabs__link">
          
  
  课程

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../assignments/2023/assignment1/" class="md-tabs__link">
          
  
  任务

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="CS231n" class="md-nav__button md-logo" aria-label="CS231n" data-md-component="logo">
      
  <img src="../logo.jpg" alt="logo">

    </a>
    CS231n
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/cs231n" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/cs231n
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    首页
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            首页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CS231n 卷积神经网络视觉识别
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    课程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    准备工作
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            准备工作
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/preparation/setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    软件设置
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/preparation/python-numpy-tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python/Numpy教程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            神经网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图像分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/linear-classify/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    线性分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/optimization-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化：随机梯度下降
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/optimization-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    反向传播
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2_5" >
        
          <label class="md-nav__link" for="__nav_2_2_5" id="__nav_2_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    神经网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2_5">
            <span class="md-nav__icon md-icon"></span>
            神经网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/neural-networks-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    创建结构
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/neural-networks-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    创建数据和损失
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/neural-networks-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    学习和评估
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/neural_network/neural-networks-case-study/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    最小神经网络案例研究
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    卷积神经网络
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            卷积神经网络
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/CNN/convolutional-networks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    结构、卷积/池化层
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/CNN/understanding-cnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    理解与可视化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../courses/CNN/transfer-learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    迁移学习与微调
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    任务
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            任务
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../assignments/2023/assignment1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    任务1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../assignments/2023/assignment2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    任务2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../assignments/2023/assignment3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    任务2
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#list-of-projects-3-digit-number-is-id-to-locate-the-poster" class="md-nav__link">
    List of Projects (3 digit number is ID to locate the poster)
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/cs231n/edit/dev/docs/poster-2018.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/cs231n/raw/dev/docs/poster-2018.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


  <h1>CS231n Poster Session 2018</h1>

<div class='fig figcenter fighighlight'>
  <img src='/assets/huang.jpg'>
</div>

<ul>
<li><strong>Location</strong>: <a href="https://www.google.com/maps/place/Jen-Hsun+Huang+Engineering+Center/@37.4277284,-122.1763852,17z/data=!3m1!4b1!4m5!3m4!1s0x808fbb2ad1efaf1d:0xe4be58a43178043f!8m2!3d37.4277284!4d-122.1741965">Jen-Hsun Huang Engineering Center</a></li>
<li><strong>Parking: Parking information can be found <a href="https://lbre.stanford.edu/sites/default/files/parking_and_circulation_map_0.pdf" title="title">here</a></strong></li>
<li><strong>Sponsor Setup Time</strong>: 11:15am - 12:00pm</li>
<li><strong>Poster Session</strong>: 12:00pm - 3:15pm</li>
<li><strong>Award Ceremony</strong>: 3:15pm - 3:30pm</li>
</ul>
<p>The 2018 Stanford CS231N poster session will showcase projects in Convolutional Neural Networks for Visual Recognition that students have worked on over the past quarter. This year, 650 students will be presenting over 300 projects. 
The topics range from Generative Adversarial Networks (GANs), healthcare and medical imaging, art and style transfer, satellite imaging, self-driving cars, video understanding and more! See the list below for the projects that will be presented.</p>
<p>Catered food and refreshments will be made available over the course of the event.</p>
<p>This poster session has been made possible thanks to generous donations from Waymo, Bloomberg, Zoox, and NVIDIA!</p>
<h3 id="list-of-projects-3-digit-number-is-id-to-locate-the-poster">List of Projects (3 digit number is ID to locate the poster)<a class="headerlink" href="#list-of-projects-3-digit-number-is-id-to-locate-the-poster" title="Permanent link">⚓︎</a></h3>
<ul>
<li><strong>101</strong>: Enhance! Image Super-Resolution</li>
<li><strong>102</strong>: Super Resolution using CNNs and GANS</li>
<li><strong>103</strong>: Modern Approaches for Real-Time Neural Style Transfer</li>
<li><strong>104</strong>: A convolutional classification approach to colorization</li>
<li><strong>105</strong>: Face swapping and harmonization using neural nets</li>
<li><strong>106</strong>: Defendr</li>
<li><strong>107</strong>: Automatic Graphic Generation from Text using GANs for Artists and Engineers</li>
<li><strong>108</strong>: Generating Novel Images of Landmarks with WGANs</li>
<li><strong>109</strong>: Generating Artwork with GANs</li>
<li><strong>110</strong>: Audio2GIF</li>
<li><strong>111</strong>: End-to-End Super Resolution Object Detection Networks</li>
<li><strong>112</strong>: Conditional Face Generation with Deep Convolutional Generative Adversarial Networks</li>
<li><strong>113</strong>: Learning a Meta-Discriminator for GANs</li>
<li><strong>115</strong>: Exploring Adversarial Input Spaces for Convolutional Neural Network Defense</li>
<li><strong>118</strong>: Contour-Aware Image-to-Image Translation</li>
<li><strong>119</strong>: Human Portrait Colorization</li>
<li><strong>120</strong>: Adversarial Image Segmentation </li>
<li><strong>121</strong>: Artwork Classification and Style Transfer</li>
<li><strong>122</strong>: Automatic Colorization through Transfer Learning</li>
<li><strong>123</strong>: CNN models for classifying emotions in art images</li>
<li><strong>124</strong>: Deep Learning for Image Completion</li>
<li><strong>125</strong>: Computer Generated Art </li>
<li><strong>127</strong>: Filter discriminators: adversarial loss for convolutional kernels</li>
<li><strong>128</strong>: Anime Character Generation with GAN</li>
<li><strong>129</strong>: Modifying the AttnGAN Discriminator for Improved Feature-Specific Text-to-Image Synthesis</li>
<li><strong>130</strong>: Data Genie </li>
<li><strong>131</strong>: Fully Unsupervised Aerial-to-Map Translation with Cycle-GAN</li>
<li><strong>132</strong>: NeuralHash: An Adversarial Steganographic Method For Robust, Imperceptible Watermarking</li>
<li><strong>133</strong>: Mapping Decision Boundaries of Convolutional Neural Network Classifiers</li>
<li><strong>134</strong>: Distributionally Robust Adversarial Training</li>
<li><strong>135</strong>: Generating realistic morphologies of neurons in rodent hippocampus with DGCAN</li>
<li><strong>136</strong>: Text2Mesh using StackGAN</li>
<li><strong>137</strong>: Detection and removal of biases using adversarial architectures</li>
<li><strong>138</strong>: Cloud Removal in Hyperspectral Satellite Images using Generative Adversarial Networks</li>
<li><strong>140</strong>: In your face! GAN Face Generation</li>
<li><strong>141</strong>: Anonymity as a Service: Addressing Perceptual Biases by Anonymizing Facial Features</li>
<li><strong>144</strong>: Global an Local Neural Style Transfer</li>
<li><strong>146</strong>: End-to-End Neural Color Transfer of Subjects in Portrait Photography</li>
<li><strong>147</strong>: Text to Artistic Image Generation with GANs</li>
<li><strong>148</strong>: Be Creative: Style Transfer Mix &amp; Match</li>
<li><strong>149</strong>: Determine the Origin of Historical Artifacts</li>
<li><strong>150</strong>: Style Transfer Incorporating Shape Deformability for Animation Genre Replication</li>
<li><strong>200</strong>: Dog Breed Identification</li>
<li><strong>203</strong>: Convolutional Neural Networks for Landmark Recognition</li>
<li><strong>204</strong>: World Landmark Recognition</li>
<li><strong>205</strong>: Distracted Driver Detection</li>
<li><strong>206</strong>: Deep Shopping: Object Detection Based Fashion Recommendation</li>
<li><strong>208</strong>: Capsule Networks on Modified Real-World Datasets</li>
<li><strong>209</strong>: Aircraft Type Recognition with Convolutional Neural Networks</li>
<li><strong>210</strong>: FloraDex: A Fine-Grained Flower Recognizer</li>
<li><strong>212</strong>: Handing Noisy Bounding-Box Annotations with Faster R-CNN</li>
<li><strong>213</strong>: A Convolutional Recurrent Attention Model for Fine-Grained Classification</li>
<li><strong>215</strong>: Probabilistic Convolutional Neural Network for Probabilistic Inference</li>
<li><strong>217</strong>: Optical Music Recognition based on Convolutional Neural Networks</li>
<li><strong>218</strong>: Fine Grain Image Classification on Dog Breeds</li>
<li><strong>219</strong>: TINE-CNN Augmentation: Automatic data augmentation for any image classification task</li>
<li><strong>220</strong>: Fashion Product Recognition in Fine-Grained Visual Categorization</li>
<li><strong>222</strong>: One-Shot Learning of Cosmetic Objects</li>
<li><strong>223</strong>: Exploring Movie Poster Classification and Generation with Deep Convolutional Neural Networks</li>
<li><strong>224</strong>: Classifying Electromagnetic Showers from Calorimeter Images with CNNs</li>
<li><strong>228</strong>: Deep Stereo Fusion: Deep Learning for Disparity Map Estimation and Image Fusion with Dual Camera Phone Imagery</li>
<li><strong>229</strong>: Automobile-Based Dual-Camera Object Segmentation</li>
<li><strong>230</strong>: Fine-grained Classification of Furniture and Home Goods Images</li>
<li><strong>231</strong>: Fine-grained Image Classification with Batch Contrastive Loss</li>
<li><strong>232</strong>: Don't Judge a Movie by its Poster</li>
<li><strong>233</strong>: Product multi-class classification using pretrained CNN models</li>
<li><strong>234</strong>: SIFT++</li>
<li><strong>237</strong>: Spatio-temporal large traffic network speed prediction using CNN</li>
<li><strong>238</strong>: Shazam for Fashion</li>
<li><strong>239</strong>: Composite Architecture for High Performance Image Classification</li>
<li><strong>240</strong>: Traffic monitoring from seismic data</li>
<li><strong>241</strong>: Image-based Merged Di-photon Identification for the ATLAS Experiment at the Large Hadron Collider</li>
<li><strong>242</strong>: DeepClean:  Deep Bayesian Restoration of Interferometric Images</li>
<li><strong>243</strong>: 3D GAN Object Generation and Reconstruction</li>
<li><strong>244</strong>: Image Segmentation for Autonomous Cars</li>
<li><strong>245</strong>: Multi-Task Facial Landmark Detection with CNN</li>
<li><strong>247</strong>: 3DNetView: Training Neural Networks to Perform 3D Image Reconstruction</li>
<li><strong>248</strong>: Architecture for Automatic Fashion Product Labeling</li>
<li><strong>249</strong>: Understanding Deforestation in the Amazon Basin with Neural Networks</li>
<li><strong>250</strong>: Gotta Train 'Em All: Classifying Pokémon using Deep Learning</li>
<li><strong>252</strong>: Movie Recommendation System Enhanced by Image Data and ConvNet</li>
<li><strong>253</strong>: Biomedical Image Segmentation for Nuclei Detection</li>
<li><strong>254</strong>: Self Attention Generative Adversarial Networks for High-Dimensional Scene Representations from Single 2D Images</li>
<li><strong>255</strong>: Learning to Detect Light Field Features</li>
<li><strong>300</strong>: Neural Techniques for Pose Guided Image Generation</li>
<li><strong>301</strong>: Conversational Group Detection With Deep Convolutional Networks</li>
<li><strong>302</strong>: Apparent Age Estimation From Facial Images</li>
<li><strong>303</strong>: American Sign Language Gesture Detection</li>
<li><strong>306</strong>: Human Body Pose Estimation</li>
<li><strong>307</strong>: Learning to Feel: Training a CNN to recognize emotion</li>
<li><strong>308</strong>: Monocular 3D Human Bounding Box Estimation</li>
<li><strong>309</strong>: Decrypting human emotions</li>
<li><strong>310</strong>: Semantic Segmentation(will update correct title)</li>
<li><strong>311</strong>: Predicting Human Emotions from Images and Captions</li>
<li><strong>312</strong>: Transformation Generalizability of Novel Objects in Human and Computational Vision</li>
<li><strong>314</strong>: Classification of Dance Styles Using CNNs</li>
<li><strong>316</strong>: Detecting Assaults in Surveillance Videos</li>
<li><strong>317</strong>: Video Hand Gesture Recognition</li>
<li><strong>319</strong>: Improving Affectnet: Emotion Classification</li>
<li><strong>320</strong>: Video Gesture Classification Using Combined RGB and Depth Features</li>
<li><strong>321</strong>: Predicting Hand Pose and Gesture from Monocular RGB Images</li>
<li><strong>402</strong>: Medical Image Super-Resolution using GANs</li>
<li><strong>403</strong>: 3D Reconstruction and Alignment of MRIs for Improved Medical Diagnostics</li>
<li><strong>405</strong>: Learning electrode probing strategy in retinal prosthesis systems</li>
<li><strong>408</strong>: PineappLeNet: PineappLeNet: Synthesizing Dynamic Contrast-Enhanced (DCE) Magnetic Resonance Data</li>
<li><strong>409</strong>: Classifying Dementia Ratings from MRI Imaging Data</li>
<li><strong>413</strong>: Protein Functional Site Detection Using Amino Acid Contact Maps</li>
<li><strong>415</strong>: Using Deep Learning for UIP Classification and Cyst Volume Calculation</li>
<li><strong>417</strong>: BoneNet: Convolutional Methods for Abnormality Detection in the Lower Extremities </li>
<li><strong>418</strong>: Does it look good? Evaluating GANs for Medical Imaging Applications</li>
<li><strong>419</strong>: Detecting Unburnt Skin Using Deep Learning</li>
<li><strong>423</strong>: Heirarchical Semantic Segmentation of Brain Tumors in MRIs using Convolutional Neural Networks</li>
<li><strong>424</strong>: Cross-Institute Histopathology Image Stain Normalization with Deep Convolutional Neural Networks</li>
<li><strong>426</strong>: Automated Burn Prognosis of Percent Total Body Surface Area</li>
<li><strong>429</strong>: Neural Stain Normalization and Unsupervised Classification of Cell Nuclei in Histopathological Breast Cancer Images</li>
<li><strong>430</strong>: Segmentation of Stroke Lesion in T1-Weighted MRIs</li>
<li><strong>431</strong>: Applying Deep Learning to Chest X-Rays for Pneumonia Detection</li>
<li><strong>432</strong>: 3D Brain Tumor Segmentation</li>
<li><strong>434</strong>: Thoracic Imaging Temporal Interpolation</li>
<li><strong>437</strong>: Automated Iris Detection</li>
<li><strong>438</strong>: Using Transfer Learning to classify Brain Tumors from Pathology Images</li>
<li><strong>440</strong>: Preprocessing Histopathology Stains with Deep Learning</li>
<li><strong>442</strong>: U-Net Architecture for Segmenting Nuclei in Medical Images</li>
<li><strong>444</strong>: Diagnosing Retinal Pathology from Optical Coherence Tomography Using VGG19 and InceptionV3</li>
<li><strong>445</strong>: Peak finding for crystallography</li>
<li><strong>446</strong>: Reconstruction of multi-shot diffusion-weighted MRI using deep learning</li>
<li><strong>450</strong>: Super-resolution MRIs with Semi-Supervised GANs</li>
<li><strong>451</strong>: Classification and Segmentation of Brain Lesions after Stroke</li>
<li><strong>452</strong>: Neural Networks for the Identification of Viable Eggs in In-vitro Fertilization</li>
<li><strong>471</strong>: Dense Convolutional Networks for Abnormality Classification in Mammograms</li>
<li><strong>455</strong>: 3D BrainNet: Brain Tumor Segmentation with Convolutional Neural Networks and Fully Connected CRFs</li>
<li><strong>456</strong>: Lung Nodule Candidate Generation and Cancer Prediction</li>
<li><strong>457</strong>: Anonymizing MRI Images via U-Net Image Segmentation</li>
<li><strong>458</strong>: Tackling Diabetic Retinopathy with Visual Recognition</li>
<li><strong>460</strong>: Unpaired Magnetic Resonance Image-to-Image Translation for Prostate using Cycle-Consistent Adversarial Networks</li>
<li><strong>461</strong>: Rethinking Radiology: An Analysis of Different Approaches to BraTS</li>
<li><strong>462</strong>: Classification Techniques for White Blood Cell Types</li>
<li><strong>470</strong>: Segmentation of Stroke Lesions in T1-Weighted Brain MRIs using Deep Learning</li>
<li><strong>500</strong>: D4QN: Distributed Deep Reinforcement Learning in the Arcade Learning Environment</li>
<li><strong>501</strong>: Single Shot Robotic Grasp Pose Detection</li>
<li><strong>502</strong>: Occupancy Grid Mapping for Robust and Efficient Learning</li>
<li><strong>504</strong>: Robotic Grasping Planning using Convolutional Neural Networks</li>
<li><strong>508</strong>: RevNet: An End-to-End Model for training self-driving simulated vehicles </li>
<li><strong>509</strong>: LiDAR &amp; RGB Fusion for 3D Bounding Box Estimation</li>
<li><strong>510</strong>: Autonomous Driving Video Segmentation with Deep Learning</li>
<li><strong>511</strong>: Recent Tesla Model X Autopilot Accident Analysis and Possible Solution via  Traffic Sign  and Lan Detection</li>
<li><strong>512</strong>: Smaller is Better: Image Compression using Deep Learning</li>
<li><strong>513</strong>: Multi-Task Learning in Visual Attribute Recognition</li>
<li><strong>514</strong>: A look at the topology of convolutional neural networks</li>
<li><strong>517</strong>: Deep Learning on LIDAR  Point Cloud for 3D Object Detection</li>
<li><strong>518</strong>: Semantic Segmentation in the Traffic Environment</li>
<li><strong>519</strong>: Suction Affordance Maps for Grasping of Diverse Objects</li>
<li><strong>521</strong>: Comparing Deep Neuroevolution to RL algorithms on Atari and Mujoco Environments</li>
<li><strong>524</strong>: Using Human Gameplay to Augment Deep Q-Networks for Crypt of the NecroDancer</li>
<li><strong>525</strong>: Comparing Learning Algorithms with Pac-Man </li>
<li><strong>526</strong>: Twist to Grasp: Rotational Regional Proposals for Grasp Detection</li>
<li><strong>529</strong>: Learning to Convolve</li>
<li><strong>530</strong>: Adversarial Examples for YOLO Object Detection</li>
<li><strong>531</strong>: High Fidelity Image Compression Using CNNs</li>
<li><strong>533</strong>: Video Object Segmentation for Autonomous Vehicles</li>
<li><strong>534</strong>: Object Detection in Autonomous Driving</li>
<li><strong>535</strong>: Improving 3D Data Resolution: Using CNNs to Upscale Resolution of LIDAR Data</li>
<li><strong>536</strong>: Semantic Segmentation on Autonomous Vehicle Data </li>
<li><strong>537</strong>: Traffic Sign Detection and Classification using Capsule Network</li>
<li><strong>539</strong>: Using t-SNE to Visualize Network Dynamics</li>
<li><strong>540</strong>: Quantization Methodology for Efficient CNN Inference</li>
<li><strong>600</strong>: Identifying Modes of Fishing from Ship Images</li>
<li><strong>601</strong>: Enhancing Climate Data Resolution using Residual Networks</li>
<li><strong>602</strong>: Detection of Cryogenic tanks</li>
<li><strong>604</strong>: Tents Density Mapping of Refugee Camp via High-Resolution Remote Sensing Imagery</li>
<li><strong>607</strong>: Convolutional Neural Networks for Radargram Segmentation</li>
<li><strong>609</strong>: Power Plant Type Classification and Numerical Prediction Using Satellite Imagery Data</li>
<li><strong>612</strong>: Semi-Supervised Image Segmentation for Satellite Imagery</li>
<li><strong>700</strong>: DeepGIFs: Using Deep Learning to Understand and Synthesize Motion</li>
<li><strong>701</strong>: Conventional Video Object Segmentation using Mask R-CNN and Online Learning</li>
<li><strong>702</strong>: Moments in Time Challenge: Spatiotemporal information extraction from sequential video inputs using joint CNN-LSTM framework</li>
<li><strong>703</strong>: Automated Visual Weak Supervision for Object Recognition in Videos</li>
<li><strong>704</strong>: Using CNNs to Identify Player Actions in Basketball Videos</li>
<li><strong>705</strong>: Video Compression with 3D CNNs</li>
<li><strong>706</strong>: Action Recognition in the Moments In Time Dataset</li>
<li><strong>707</strong>: Convolutional Neural Networks for MLB Pitch Recognition</li>
<li><strong>711</strong>: Video Classification on the YouTube-8M Dataset</li>
<li><strong>712</strong>: A Multi-Faceted Approach to Video Action Classification</li>
<li><strong>713</strong>: Basketball Shot Quality Assessment with Deep Learning</li>
<li><strong>714</strong>: Moments in Time: Deep Action Recognition</li>
<li><strong>800</strong>: Spotting and Transcribing Structured Nutrition Information from Product Images</li>
<li><strong>802</strong>: A Novel Approach using Weak Supervision to Label Digital Screenshots\ for Behavioral Analysis with Transfer Learning</li>
<li><strong>803</strong>: End-To-End Trainable Model for Text Recognition</li>
<li><strong>804</strong>: Converting Handwriting to Latex</li>
<li><strong>807</strong>: Layerwise Quantization for Neural Networks</li>
<li><strong>808</strong>: Image Retrieval and Image-Text Feature Alignment</li>
<li><strong>809</strong>: Emoji-Language Image Captioning</li>
<li><strong>810</strong>: Optimizing Reddit Posts</li>
<li><strong>811</strong>: Culinary Images' Feature-Extraction And Recipe Generation Using Deep Convolutional Neural Network</li>
<li><strong>812</strong>: Automatic Code Generation from UI Screenshots</li>
<li><strong>813</strong>: GUCCI GAN: Grouped Unique Contextually-Classified Inpainting GAN</li>
<li><strong>814</strong>: Adversarial Visual Question Answering</li>
<li><strong>816</strong>: Handwritten Mathematics to LaTeX Code</li>
<li><strong>817</strong>: Image captioning with attention</li>
<li><strong>818</strong>: Identifying and Solving CAPTCHAs with Deep Learning</li>
<li><strong>819</strong>: Mobile-Focused Networks for Classification of Chinese Text in the Wild</li>
<li><strong>820</strong>: End-to-end Dense Video Captioning with Reinforcement Learning</li>
<li><strong>823</strong>: Image Captioning using Policy Gradient Method</li>
<li><strong>825</strong>: Chinese Character Synthesization From Components</li>
<li><strong>826</strong>: Photo Quality Assessment with Deep CNNs</li>
<li><strong>827</strong>: Bridging 3D shape and natural language</li>
<li><strong>828</strong>: Neural Image Captioning on MSCOCO Dataset</li>
</ul>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">September 16, 2023</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">September 16, 2023</span>
      
    
  </small>
</div>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        对当前页面有任何疑问吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              感谢您的反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              感谢您的反馈！请点击这里<a href="https://github.com/EanYang7/cs231n/issues" target="_blank" rel="noopener">这里</a>提供问题反馈.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/EanYang7/cs231n" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.path", "toc.follow", "content.action.edit", "content.action.view", "content.code.copy"], "search": "../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.dff1b7c8.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>